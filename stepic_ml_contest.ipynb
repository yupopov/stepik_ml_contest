{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка наборов данных для обучения\n",
    "events = pd.read_csv(\"./datasets/event_data_train.zip\")\n",
    "submissions = pd.read_csv(\"./datasets/submissions_data_train.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание целевой переменной 'is_gone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target(submissions_df, threshold=39):\n",
    "    # количество успешно решенных степов\n",
    "    users_count_correct = submissions_df[\n",
    "        submissions_df.submission_status == 'correct'\n",
    "    ].groupby('user_id').agg({\n",
    "        'step_id': 'count'\n",
    "    }).reset_index().rename(columns={'step_id': 'corrects'})\n",
    "    \n",
    "    # is_gone = 1, если пройдено > threshold           \n",
    "    users_count_correct['is_gone'] = (users_count_correct.corrects > threshold).astype('int')\n",
    "    \n",
    "    return users_count_correct.drop(['corrects'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Первые 2 дня на курсе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_df_by_time(df, days=2):\n",
    "    users_min_timestamp = df.groupby('user_id').agg(\n",
    "        {'timestamp': 'min'}\n",
    "    ).reset_index().rename(\n",
    "        {'timestamp': 'min_timestamp'}, axis=1\n",
    "    )\n",
    "    users_min_timestamp['min_timestamp'] += 60 * 60 * 24 * days\n",
    "    \n",
    "    events_data_d = pd.merge(df, users_min_timestamp, how='inner', on='user_id')\n",
    "    cond = events_data_d['timestamp'] <= events_data_d['min_timestamp']\n",
    "    events_data_d = events_data_d[cond]\n",
    "\n",
    "    assert events_data_d.user_id.nunique() == df.user_id.nunique()\n",
    "    return events_data_d.drop(['min_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные первых двух дней прохождения курса\n",
    "submissions_2d = cut_df_by_time(submissions)\n",
    "events_2d = cut_df_by_time(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_features(events_df, submissions_df):\n",
    "    # количество каждого значения action для юзера\n",
    "    users_events = events_df.pivot_table(\n",
    "        index='user_id',\n",
    "        columns='action',\n",
    "        values='step_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    \n",
    "    # количество каждого значения submission_status для юзера\n",
    "    users_submissions = submissions_df.pivot_table(\n",
    "        index='user_id',\n",
    "        columns='submission_status',\n",
    "        values='step_id',\n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    ).reset_index()\n",
    "    \n",
    "    base_train_df = users_events.merge(users_submissions, on='user_id', how='outer').fillna(0)\n",
    "    assert base_train_df.user_id.nunique() == events_df.user_id.nunique()\n",
    "    return base_train_df\n",
    "      \n",
    "    \n",
    "def get_time_features(events_df, submissions_df):\n",
    "    events_df['date'] = (pd.to_datetime(events_df.timestamp, unit='s')).dt.date\n",
    "    events_tf = events_df.groupby('user_id').agg({\n",
    "        'date': 'nunique',  # количество уникальных дней в events\n",
    "        'timestamp': ['min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # количество часов в events\n",
    "    events_tf['hour_evn'] = round(\n",
    "        (events_tf.timestamp['max'] - events_tf.timestamp['min']) / (60*60),\n",
    "        0\n",
    "    ).astype('int')\n",
    "    events_tf['day'] = events_tf.date['nunique']\n",
    "    # день недели начала прохождения\n",
    "    events_tf['dayweek_evn'] = (pd.to_datetime(events_tf.timestamp['min'], unit='s')).dt.dayofweek\n",
    "\n",
    "    submissions_tf = submissions_df.groupby('user_id').agg({\n",
    "        'timestamp': ['min', 'max']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # количество часов в submissions\n",
    "    submissions_tf['hour_sub'] = round(\n",
    "        (submissions_tf.timestamp['max'] - submissions_tf.timestamp['min']) / (60*60), \n",
    "        0\n",
    "    )\n",
    "    \n",
    "    time_features_df = events_tf.merge(submissions_tf[['user_id', 'hour_sub']], on='user_id', how='outer').fillna(-1)\n",
    "    assert time_features_df.user_id.nunique() == events_df.user_id.nunique()\n",
    "    return time_features_df.drop(['timestamp', 'date'], axis=1)\n",
    "\n",
    "\n",
    "def get_step_count(df, name):\n",
    "    step_count = df.groupby('user_id').agg({\n",
    "         'step_id': 'nunique'\n",
    "     }).reset_index().rename(columns={'step_id': name})\n",
    "    \n",
    "    return step_count\n",
    "    \n",
    "    \n",
    "def get_steps_ohe_features(submissions_df):\n",
    "    step_ids = [\n",
    "        31971,  31972,  31976,  31977,  31978,  31979,  31981,  \n",
    "        31983,  31986,  31991,  32031,  32075,  32089,  32173,  \n",
    "        32174,  32175,  32198,  32202,  32206,  32219,  32796,  \n",
    "        32812,  32929,  33332,  33334,  33367,  33413,  33415,  \n",
    "        33418,  33420,  33480,  33481,  33482,  33487,  33488,  \n",
    "        33534,  33536,  33540,  33673,  33674,  33675,  33677,  \n",
    "        33684,  33685,  120745\n",
    "    ]\n",
    "    \n",
    "    # прошел ли пользователь степы из step_ids\n",
    "    ohe_step = pd.get_dummies(\n",
    "        submissions_df[(submissions_df.submission_status == 'correct') \n",
    "                       & (submissions_df.step_id.isin(step_ids))], \n",
    "        columns=['step_id']\n",
    "    )\n",
    "    steps_features = ohe_step.groupby('user_id').sum().reset_index()\n",
    "    \n",
    "    # отбор колонок с информацие о прохождении степов\n",
    "    steps_features.rename(columns={'user_id': 'step_id_user_id'}, inplace=True)\n",
    "    steps_features = steps_features.loc[:,steps_features.columns.str.startswith('step_id_')]\n",
    "    steps_features.rename(columns={'step_id_user_id': 'user_id'}, inplace=True)\n",
    "    \n",
    "    return steps_features\n",
    "    \n",
    "\n",
    "def get_custom_features(df):\n",
    "    # отобранные фичи\n",
    "    df['dis_to_cor'] = df.discovered - df.correct\n",
    "    df['loss_step'] = df.started_attempt - df.correct\n",
    "    df['step_pas'] = df.evn_steps - df.passed\n",
    "    df['start_pas'] = df.started_attempt - df.passed\n",
    "    df['all_sum'] = df[['correct', 'wrong', 'discovered', 'passed', 'started_attempt', 'viewed']].sum(axis=1)\n",
    "    df['all_pass'] = df.all_sum - df.evn_steps\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_work_df(events_train, submissions_train, target=None):\n",
    "    '''\n",
    "    Сборка датасета для работы с моделью\n",
    "    '''\n",
    "    df = get_base_features(events_train, submissions_train)\n",
    "    \n",
    "    time_features = get_time_features(events_train, submissions_train)\n",
    "    df = df.merge(time_features, on='user_id')\n",
    "    df.rename(columns={\n",
    "        ('hour_evn', ''): 'hour_evn', \n",
    "        ('day', ''): 'day',\n",
    "        ('dayweek_evn', ''): 'dayweek_evn',  \n",
    "        ('hour_sub', ''): 'hour_sub'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    df = df.merge(get_step_count(submissions_train, 'sub_steps'), on='user_id', how='outer').fillna(0)\n",
    "    df = df.merge(get_step_count(events_train, 'evn_steps'), on='user_id')\n",
    "    df = df.merge(get_steps_ohe_features(submissions_train), on='user_id', how='outer').fillna(0)\n",
    "\n",
    "    df = get_custom_features(df)\n",
    "    \n",
    "    if target is not None:\n",
    "        # добавление целевой переменной\n",
    "        df = df.merge(target, on='user_id', how='outer').fillna(0)\n",
    "\n",
    "    return df.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunda\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n",
      "C:\\Users\\sunda\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_df = create_work_df(events_2d, submissions_2d, target=get_target(submissions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import datetime as dt\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отбор юзеров для test и train\n",
    "users_ids = train_df.user_id.unique()\n",
    "np.random.seed(17)\n",
    "np.random.shuffle(users_ids)\n",
    "test_sz = int(len(users_ids) * 0.2)\n",
    "train_sz = len(users_ids) - test_sz\n",
    "train_users = users_ids[:train_sz]\n",
    "test_users = users_ids[-test_sz:]\n",
    "# Проверка что пользователи не пересекаются\n",
    "assert len(np.intersect1d(train_users, test_users)) == 0\n",
    "\n",
    "# теперь делим данные\n",
    "train = train_df[train_df.user_id.isin(train_users)]\n",
    "test = train_df[train_df.user_id.isin(test_users)]\n",
    "\n",
    "X_train = train.drop(['user_id', 'is_gone'], axis=1)\n",
    "y_train = train['is_gone']\n",
    "\n",
    "X_test = test.drop(['user_id', 'is_gone'], axis=1)\n",
    "y_test = test['is_gone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single(X_train, X_test, y_train, y_test, random_state=42):\n",
    "    '''\n",
    "    Логика обучения модели\n",
    "    '''\n",
    "    eta = 0.1\n",
    "    max_depth= 3 \n",
    "    subsample = 1\n",
    "    colsample_bytree = 1\n",
    "    min_chil_weight=1\n",
    "    start_time = time.time()\n",
    "\n",
    "    print('XGBoost params. ETA: {}, MAX_DEPTH: {}, SUBSAMPLE: {}, COLSAMPLE_BY_TREE: {}'.format(eta, \n",
    "                                                                                                max_depth, \n",
    "                                                                                                subsample, \n",
    "                                                                                                colsample_bytree))\n",
    "    params = {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"booster\" : \"gbtree\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"eta\": eta,\n",
    "        \"tree_method\": 'exact',\n",
    "        \"max_depth\": max_depth,\n",
    "        \"subsample\": subsample,\n",
    "        \"colsample_bytree\": colsample_bytree,\n",
    "        \"silent\": 1,\n",
    "        \"min_chil_weight\":min_chil_weight,\n",
    "        \"seed\": random_state\n",
    "    }\n",
    "    num_boost_round = 500\n",
    "    early_stopping_rounds = 20\n",
    "    test_size = 0.1\n",
    "    print('Length train:', len(X_train.index))\n",
    "    print('Length test:', len(X_test.index))\n",
    "    dtrain = xgb.DMatrix(X_train, y_train, missing=-99)\n",
    "    dvalid = xgb.DMatrix(X_test, y_test, missing =-99)\n",
    "\n",
    "    watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "    gbm = xgb.train(\n",
    "        params, dtrain, num_boost_round, evals=watchlist, \n",
    "        early_stopping_rounds=early_stopping_rounds, verbose_eval=False) \n",
    "    \n",
    "    return gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model..  0:00:00\n",
      "XGBoost params. ETA: 0.1, MAX_DEPTH: 3, SUBSAMPLE: 1, COLSAMPLE_BY_TREE: 1\n",
      "Length train: 15388\n",
      "Length test: 3846\n",
      "0.901962\n",
      "0:00:01.133346\n"
     ]
    }
   ],
   "source": [
    "# обучение модели\n",
    "start_time = dt.datetime.now()\n",
    "features = list(X_train.columns.values)\n",
    "print(\"Building model.. \",dt.datetime.now()-start_time)\n",
    "\n",
    "gbm = run_single(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(gbm.best_score)\n",
    "print(dt.datetime.now()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunda\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3812: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  new_axis = axis.drop(labels, errors=errors)\n",
      "C:\\Users\\sunda\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:522: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "events_t = pd.read_csv(\"./datasets/events_data_test.zip\")\n",
    "submissions_t = pd.read_csv(\"./datasets/submission_data_test.zip\")\n",
    "\n",
    "# Поднготовка данных\n",
    "X_pred = create_work_df(events_t, submissions_t)\n",
    "dpred = xgb.DMatrix(X_pred.drop(['user_id'], axis=1), missing=-99)\n",
    "\n",
    "pred_proba = gbm.predict(dpred)\n",
    "X_pred['is_gone'] = pred_proba\n",
    "\n",
    "# сохранение данных\n",
    "X_pred[['user_id', 'is_gone']].to_csv(f'my_pdedict_{str(gbm.best_score)[2:6]}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данное решение дает ROC score: 0.8937"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC AUC зависит от способа разбиения тренеровочных данных на train и test. Отсюда вывод, что в тренеровочных данных есть юзеры, которые вели себя не естественно. Новая гипотеза: найти удалить тех, кто сильно отличается от представителей своего класса."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
